{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Few to No Labels\n",
    "\n",
    "At the start of every project, the first question any data scientist asks? Is there any labelled data? Answer's mostly no or little bit. And on top of client's expectation that our fancy machine learning models should still perform well. One obvious apporach is annotate more data, but this is more expensive if each annotation has to be validated by a domain expert.\n",
    "\n",
    "Fortunaley there are several methods that are suited for dealing with few to no labels. Like *Zero-shot* in GPT-3 where it perfoms over a diverse range of tasks with a few dozen examples.\n",
    "\n",
    "In general, the best-performing method will depend upon task, data, how much of the data is labeled. \n",
    "\n",
    "*The below picture will guide us through the process of picking the most appropriate method*\n",
    "![alt](../notes/images/9-dealing-with-few-to-no-labels/technqiques-to-deal-with-less-to-no-labelled-data.png)\n",
    "\n",
    "Let's walk through this decision tree:\n",
    "\n",
    "1. Is labeld data available?\n",
    "\n",
    "Evan a handful of labeled of labeled samples can make a difference with regards to which method works best. If no labeld data is available then we can start with zero-shot learning which often sets a strong baseline to work from.\n",
    "\n",
    "2. How many labels?\n",
    "\n",
    "If we lots of labelled training data available then we can use the fine tuning approach used in [notebook 2](../notebooks/2-text-classification.ipynb)\n",
    "\n",
    "3. Is there unlabeled data available?\n",
    "\n",
    "If we have a handful of labeled samples it can help immensley if we have access to large amounts ot unlabeled data. If we have access to unlabeled data, we can use it to fine-tune the language model on the domain before training the classifier, or use more sophisticated methods like unsupervised data augmentation(UDA) or uncertainy-aware self-training(UST). If no unlabeled data is available, we can't annotate more data. In this case we can use few-shot learning or use the embeddings from a pretrained language model to perform lookups with a nearest neighbor search.\n",
    "\n",
    "Int this notebook, we'll work our way through the decision tree by tackling a common problem facing many support teams that use issue trackers like Jira or Github to assist their users: tagging issues with metadata based on the issue's description. These tags define issue type,product causing the issue, responsible team. Automating the process will have an big impact on productivity and enables the support teams to focus on helping the users. In this notebook, we'll use issues associated with a populat open source project: Transformers. Let's now take a look at what information is available in these issues, what is the task and how to get the data.\n",
    "\n",
    "> **Note:** The methods used in this notebooks will work well for text classification, but other techniques such as data augmentation may be necessary for dealing with more complex tasks like named entity recognition, question answering or summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Github Issues Tagger\n",
    "\n",
    "If we navgate to [issues tab](https://github.com/huggingface/transformers/issues) of transformers, we'll have each issues with title, description, set of tags or labels to chracterize the issue. The supervised learning task: given a title, description of an issue, predict one or more labels, this means we are dealing with multlable classification problem. \n",
    "\n",
    "*Single issue*\n",
    "![alt](../notes/images/9-dealing-with-few-to-no-labels/singe-issue.png)\n",
    "\n",
    "Now we've seen how the Github Issues look like, next let's see how to download and create our dataset.\n",
    "\n",
    "To grab all repository's issues, we'll use the [GitHub REST API](https://docs.github.com/en/rest?apiVersion=2022-11-28) to poll the [Issues endpoint](https://docs.github.com/en/rest/issues#list-repository-issues). This endpoint returns a list of json objects, with each object contatining, issue, title, description, whether issue is open or close, owho opend it etc.\n",
    "\n",
    "Since it takes a while to fetch all issues, we'll use the *github-issues-transformers-json* file. Along with `fetch_issues()` function to download them.\n",
    "\n",
    "> **Note:** The GitHub REST API treats pull requests as issues, so our dataset contains both issues and pull requests. To keep things simple. we'' develop our classifier for both issue types, althoug in practice we can have two seperated classifiers to have more fine-grained control over the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def fetch_issues(\n",
    "    owner=\"huggingface\",\n",
    "    repo=\"transformers\",\n",
    "    num_issues=10_000,\n",
    "    rate_limit=5_000,\n",
    "):\n",
    "    batch = []\n",
    "    all_issues = []\n",
    "    per_page = 100 # Number of issues to return per page\n",
    "    num_pages = math.ceil(num_issues / per_page)\n",
    "    base_url = \"https://api.github.com/repos\"\n",
    "\n",
    "    for page in tqdm(range(num_pages)):\n",
    "        query = f\"issues?page={page}&per_page={per_page}&state=all\"\n",
    "        issues = requests.get(f\"{base_url}/{owner}/{repo}/{query}\")\n",
    "        batch.extend(issues)\n",
    "\n",
    "        if len(batch) > rate_limit and len(all_issues) < num_issues:\n",
    "            all_issues.extend(batch)\n",
    "            batch = [] # Flush batch for next time period\n",
    "            print(f\"Reached Github rate limit. Sleeping for one hour...\")\n",
    "            time.sleep(60 * 60 + 1)\n",
    "    all_issues.extend(batch)\n",
    "    df = pd.DataFrrame.from_records(all_issues)\n",
    "    df.to_json(f\"github-issues-{repo}.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will download all the issues in batches to avoid exceeding GitHub's limit on number of requests per hour. Let's download the file.\n",
    "\n",
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (9930, 26)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "dataset_url = \"https://git.io/nlp-with-transformers\"\n",
    "df_issues = pd.read_json(dataset_url, lines=True)\n",
    "print(f\"DataFrame shape: {df_issues.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>repository_url</th>\n",
       "      <th>labels_url</th>\n",
       "      <th>comments_url</th>\n",
       "      <th>events_url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>id</th>\n",
       "      <th>node_id</th>\n",
       "      <th>number</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>milestone</th>\n",
       "      <th>comments</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>closed_at</th>\n",
       "      <th>author_association</th>\n",
       "      <th>active_lock_reason</th>\n",
       "      <th>body</th>\n",
       "      <th>performed_via_github_app</th>\n",
       "      <th>pull_request</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://github.com/huggingface/transformers/is...</td>\n",
       "      <td>849568459</td>\n",
       "      <td>MDU6SXNzdWU4NDk1Njg0NTk=</td>\n",
       "      <td>11046</td>\n",
       "      <td>Potential incorrect application of layer norm ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-03 03:37:32</td>\n",
       "      <td>2021-04-03 03:37:32</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>None</td>\n",
       "      <td>In BlenderbotSmallDecoder,  layer norm is appl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://github.com/huggingface/transformers/is...</td>\n",
       "      <td>849544374</td>\n",
       "      <td>MDU6SXNzdWU4NDk1NDQzNzQ=</td>\n",
       "      <td>11045</td>\n",
       "      <td>Multi-GPU seq2seq example evaluation significa...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-03 00:52:24</td>\n",
       "      <td>2021-04-03 00:52:24</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>None</td>\n",
       "      <td>\\r\\n### Who can help\\r\\n@patil-suraj @sgugger ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://github.com/huggingface/transformers/is...</td>\n",
       "      <td>849529761</td>\n",
       "      <td>MDU6SXNzdWU4NDk1Mjk3NjE=</td>\n",
       "      <td>11044</td>\n",
       "      <td>[DeepSpeed] ZeRO stage 3 integration: getting ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-02 23:40:42</td>\n",
       "      <td>2021-04-03 00:00:18</td>\n",
       "      <td>NaT</td>\n",
       "      <td>COLLABORATOR</td>\n",
       "      <td>None</td>\n",
       "      <td>**[This is not yet alive, preparing for the re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://github.com/huggingface/transformers/is...</td>\n",
       "      <td>849499734</td>\n",
       "      <td>MDU6SXNzdWU4NDk0OTk3MzQ=</td>\n",
       "      <td>11043</td>\n",
       "      <td>Can't load model to estimater</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-02 21:51:44</td>\n",
       "      <td>2021-04-02 21:51:44</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>None</td>\n",
       "      <td>I was trying to follow the Sagemaker instructi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://github.com/huggingface/transformers/is...</td>\n",
       "      <td>849274362</td>\n",
       "      <td>MDU6SXNzdWU4NDkyNzQzNjI=</td>\n",
       "      <td>11042</td>\n",
       "      <td>[LXMERT] Unclear what img_tensorize does with ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-04-02 15:12:57</td>\n",
       "      <td>2021-04-02 15:15:07</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NONE</td>\n",
       "      <td>None</td>\n",
       "      <td>## Environment info\\r\\n\\r\\n- `transformers` ve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9925</th>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://github.com/huggingface/transformers/pu...</td>\n",
       "      <td>486208136</td>\n",
       "      <td>MDExOlB1bGxSZXF1ZXN0MzExNzA2NjQ5</td>\n",
       "      <td>1127</td>\n",
       "      <td>DistilBERT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-28 07:34:11</td>\n",
       "      <td>2020-01-09 13:36:31</td>\n",
       "      <td>2019-08-28 14:43:10</td>\n",
       "      <td>MEMBER</td>\n",
       "      <td>None</td>\n",
       "      <td>Preparing the release for DistilBERT (smaller,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'url': 'https://api.github.com/repos/huggingf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9926</th>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://github.com/huggingface/transformers/is...</td>\n",
       "      <td>486120054</td>\n",
       "      <td>MDU6SXNzdWU0ODYxMjAwNTQ=</td>\n",
       "      <td>1126</td>\n",
       "      <td>Bert initialization</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-28 02:01:59</td>\n",
       "      <td>2019-09-02 06:53:22</td>\n",
       "      <td>2019-09-02 06:53:22</td>\n",
       "      <td>NONE</td>\n",
       "      <td>None</td>\n",
       "      <td>When I train bert model from scratch, it can n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9927</th>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://github.com/huggingface/transformers/is...</td>\n",
       "      <td>486021648</td>\n",
       "      <td>MDU6SXNzdWU0ODYwMjE2NDg=</td>\n",
       "      <td>1125</td>\n",
       "      <td>UnicodeDecodeError: 'charmap' codec can't deco...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-08-27 20:37:09</td>\n",
       "      <td>2020-11-04 14:37:42</td>\n",
       "      <td>2019-09-01 23:18:49</td>\n",
       "      <td>NONE</td>\n",
       "      <td>None</td>\n",
       "      <td>## üêõ Bug\\r\\n\\r\\n&lt;!-- Important information --&gt;...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9928</th>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://github.com/huggingface/transformers/is...</td>\n",
       "      <td>485975571</td>\n",
       "      <td>MDU6SXNzdWU0ODU5NzU1NzE=</td>\n",
       "      <td>1124</td>\n",
       "      <td>XLNet resize embedding size ERROR</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-27 18:52:10</td>\n",
       "      <td>2019-09-02 21:14:56</td>\n",
       "      <td>2019-09-02 21:14:56</td>\n",
       "      <td>NONE</td>\n",
       "      <td>None</td>\n",
       "      <td>## ‚ùì Questions &amp; Help\\r\\n\\r\\nI add new tokens ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9929</th>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://api.github.com/repos/huggingface/trans...</td>\n",
       "      <td>https://github.com/huggingface/transformers/is...</td>\n",
       "      <td>485876617</td>\n",
       "      <td>MDU6SXNzdWU0ODU4NzY2MTc=</td>\n",
       "      <td>1123</td>\n",
       "      <td>Extracting Features Example</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-08-27 15:21:11</td>\n",
       "      <td>2019-12-12 11:48:51</td>\n",
       "      <td>2019-12-12 11:48:51</td>\n",
       "      <td>NONE</td>\n",
       "      <td>None</td>\n",
       "      <td>## ‚ùì Questions &amp; Help\\r\\n\\r\\nHello. \\r\\n\\r\\nSo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9930 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url  \\\n",
       "0     https://api.github.com/repos/huggingface/trans...   \n",
       "1     https://api.github.com/repos/huggingface/trans...   \n",
       "2     https://api.github.com/repos/huggingface/trans...   \n",
       "3     https://api.github.com/repos/huggingface/trans...   \n",
       "4     https://api.github.com/repos/huggingface/trans...   \n",
       "...                                                 ...   \n",
       "9925  https://api.github.com/repos/huggingface/trans...   \n",
       "9926  https://api.github.com/repos/huggingface/trans...   \n",
       "9927  https://api.github.com/repos/huggingface/trans...   \n",
       "9928  https://api.github.com/repos/huggingface/trans...   \n",
       "9929  https://api.github.com/repos/huggingface/trans...   \n",
       "\n",
       "                                         repository_url  \\\n",
       "0     https://api.github.com/repos/huggingface/trans...   \n",
       "1     https://api.github.com/repos/huggingface/trans...   \n",
       "2     https://api.github.com/repos/huggingface/trans...   \n",
       "3     https://api.github.com/repos/huggingface/trans...   \n",
       "4     https://api.github.com/repos/huggingface/trans...   \n",
       "...                                                 ...   \n",
       "9925  https://api.github.com/repos/huggingface/trans...   \n",
       "9926  https://api.github.com/repos/huggingface/trans...   \n",
       "9927  https://api.github.com/repos/huggingface/trans...   \n",
       "9928  https://api.github.com/repos/huggingface/trans...   \n",
       "9929  https://api.github.com/repos/huggingface/trans...   \n",
       "\n",
       "                                             labels_url  \\\n",
       "0     https://api.github.com/repos/huggingface/trans...   \n",
       "1     https://api.github.com/repos/huggingface/trans...   \n",
       "2     https://api.github.com/repos/huggingface/trans...   \n",
       "3     https://api.github.com/repos/huggingface/trans...   \n",
       "4     https://api.github.com/repos/huggingface/trans...   \n",
       "...                                                 ...   \n",
       "9925  https://api.github.com/repos/huggingface/trans...   \n",
       "9926  https://api.github.com/repos/huggingface/trans...   \n",
       "9927  https://api.github.com/repos/huggingface/trans...   \n",
       "9928  https://api.github.com/repos/huggingface/trans...   \n",
       "9929  https://api.github.com/repos/huggingface/trans...   \n",
       "\n",
       "                                           comments_url  \\\n",
       "0     https://api.github.com/repos/huggingface/trans...   \n",
       "1     https://api.github.com/repos/huggingface/trans...   \n",
       "2     https://api.github.com/repos/huggingface/trans...   \n",
       "3     https://api.github.com/repos/huggingface/trans...   \n",
       "4     https://api.github.com/repos/huggingface/trans...   \n",
       "...                                                 ...   \n",
       "9925  https://api.github.com/repos/huggingface/trans...   \n",
       "9926  https://api.github.com/repos/huggingface/trans...   \n",
       "9927  https://api.github.com/repos/huggingface/trans...   \n",
       "9928  https://api.github.com/repos/huggingface/trans...   \n",
       "9929  https://api.github.com/repos/huggingface/trans...   \n",
       "\n",
       "                                             events_url  \\\n",
       "0     https://api.github.com/repos/huggingface/trans...   \n",
       "1     https://api.github.com/repos/huggingface/trans...   \n",
       "2     https://api.github.com/repos/huggingface/trans...   \n",
       "3     https://api.github.com/repos/huggingface/trans...   \n",
       "4     https://api.github.com/repos/huggingface/trans...   \n",
       "...                                                 ...   \n",
       "9925  https://api.github.com/repos/huggingface/trans...   \n",
       "9926  https://api.github.com/repos/huggingface/trans...   \n",
       "9927  https://api.github.com/repos/huggingface/trans...   \n",
       "9928  https://api.github.com/repos/huggingface/trans...   \n",
       "9929  https://api.github.com/repos/huggingface/trans...   \n",
       "\n",
       "                                               html_url         id  \\\n",
       "0     https://github.com/huggingface/transformers/is...  849568459   \n",
       "1     https://github.com/huggingface/transformers/is...  849544374   \n",
       "2     https://github.com/huggingface/transformers/is...  849529761   \n",
       "3     https://github.com/huggingface/transformers/is...  849499734   \n",
       "4     https://github.com/huggingface/transformers/is...  849274362   \n",
       "...                                                 ...        ...   \n",
       "9925  https://github.com/huggingface/transformers/pu...  486208136   \n",
       "9926  https://github.com/huggingface/transformers/is...  486120054   \n",
       "9927  https://github.com/huggingface/transformers/is...  486021648   \n",
       "9928  https://github.com/huggingface/transformers/is...  485975571   \n",
       "9929  https://github.com/huggingface/transformers/is...  485876617   \n",
       "\n",
       "                               node_id  number  \\\n",
       "0             MDU6SXNzdWU4NDk1Njg0NTk=   11046   \n",
       "1             MDU6SXNzdWU4NDk1NDQzNzQ=   11045   \n",
       "2             MDU6SXNzdWU4NDk1Mjk3NjE=   11044   \n",
       "3             MDU6SXNzdWU4NDk0OTk3MzQ=   11043   \n",
       "4             MDU6SXNzdWU4NDkyNzQzNjI=   11042   \n",
       "...                                ...     ...   \n",
       "9925  MDExOlB1bGxSZXF1ZXN0MzExNzA2NjQ5    1127   \n",
       "9926          MDU6SXNzdWU0ODYxMjAwNTQ=    1126   \n",
       "9927          MDU6SXNzdWU0ODYwMjE2NDg=    1125   \n",
       "9928          MDU6SXNzdWU0ODU5NzU1NzE=    1124   \n",
       "9929          MDU6SXNzdWU0ODU4NzY2MTc=    1123   \n",
       "\n",
       "                                                  title  ... milestone  \\\n",
       "0     Potential incorrect application of layer norm ...  ...       NaN   \n",
       "1     Multi-GPU seq2seq example evaluation significa...  ...       NaN   \n",
       "2     [DeepSpeed] ZeRO stage 3 integration: getting ...  ...       NaN   \n",
       "3                         Can't load model to estimater  ...       NaN   \n",
       "4     [LXMERT] Unclear what img_tensorize does with ...  ...       NaN   \n",
       "...                                                 ...  ...       ...   \n",
       "9925                                         DistilBERT  ...       NaN   \n",
       "9926                                Bert initialization  ...       NaN   \n",
       "9927  UnicodeDecodeError: 'charmap' codec can't deco...  ...       NaN   \n",
       "9928                  XLNet resize embedding size ERROR  ...       NaN   \n",
       "9929                        Extracting Features Example  ...       NaN   \n",
       "\n",
       "     comments          created_at          updated_at           closed_at  \\\n",
       "0           0 2021-04-03 03:37:32 2021-04-03 03:37:32                 NaT   \n",
       "1           0 2021-04-03 00:52:24 2021-04-03 00:52:24                 NaT   \n",
       "2           0 2021-04-02 23:40:42 2021-04-03 00:00:18                 NaT   \n",
       "3           0 2021-04-02 21:51:44 2021-04-02 21:51:44                 NaT   \n",
       "4           0 2021-04-02 15:12:57 2021-04-02 15:15:07                 NaT   \n",
       "...       ...                 ...                 ...                 ...   \n",
       "9925        2 2019-08-28 07:34:11 2020-01-09 13:36:31 2019-08-28 14:43:10   \n",
       "9926        2 2019-08-28 02:01:59 2019-09-02 06:53:22 2019-09-02 06:53:22   \n",
       "9927        4 2019-08-27 20:37:09 2020-11-04 14:37:42 2019-09-01 23:18:49   \n",
       "9928        1 2019-08-27 18:52:10 2019-09-02 21:14:56 2019-09-02 21:14:56   \n",
       "9929        4 2019-08-27 15:21:11 2019-12-12 11:48:51 2019-12-12 11:48:51   \n",
       "\n",
       "     author_association  active_lock_reason  \\\n",
       "0                  NONE                None   \n",
       "1                  NONE                None   \n",
       "2          COLLABORATOR                None   \n",
       "3                  NONE                None   \n",
       "4                  NONE                None   \n",
       "...                 ...                 ...   \n",
       "9925             MEMBER                None   \n",
       "9926               NONE                None   \n",
       "9927               NONE                None   \n",
       "9928               NONE                None   \n",
       "9929               NONE                None   \n",
       "\n",
       "                                                   body  \\\n",
       "0     In BlenderbotSmallDecoder,  layer norm is appl...   \n",
       "1     \\r\\n### Who can help\\r\\n@patil-suraj @sgugger ...   \n",
       "2     **[This is not yet alive, preparing for the re...   \n",
       "3     I was trying to follow the Sagemaker instructi...   \n",
       "4     ## Environment info\\r\\n\\r\\n- `transformers` ve...   \n",
       "...                                                 ...   \n",
       "9925  Preparing the release for DistilBERT (smaller,...   \n",
       "9926  When I train bert model from scratch, it can n...   \n",
       "9927  ## üêõ Bug\\r\\n\\r\\n<!-- Important information -->...   \n",
       "9928  ## ‚ùì Questions & Help\\r\\n\\r\\nI add new tokens ...   \n",
       "9929  ## ‚ùì Questions & Help\\r\\n\\r\\nHello. \\r\\n\\r\\nSo...   \n",
       "\n",
       "     performed_via_github_app  \\\n",
       "0                         NaN   \n",
       "1                         NaN   \n",
       "2                         NaN   \n",
       "3                         NaN   \n",
       "4                         NaN   \n",
       "...                       ...   \n",
       "9925                      NaN   \n",
       "9926                      NaN   \n",
       "9927                      NaN   \n",
       "9928                      NaN   \n",
       "9929                      NaN   \n",
       "\n",
       "                                           pull_request  \n",
       "0                                                  None  \n",
       "1                                                  None  \n",
       "2                                                  None  \n",
       "3                                                  None  \n",
       "4                                                  None  \n",
       "...                                                 ...  \n",
       "9925  {'url': 'https://api.github.com/repos/huggingf...  \n",
       "9926                                               None  \n",
       "9927                                               None  \n",
       "9928                                               None  \n",
       "9929                                               None  \n",
       "\n",
       "[9930 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
